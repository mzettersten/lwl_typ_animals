---
title: "Analysis CATegories"
author: "Anonymized"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

## Load packages

```{r setup, message=FALSE}

library(tidyverse)
library(janitor)
library(cowplot)
library(here)
library(readxl)
library(Matrix)
library(lme4)
library(lmerTest)
library(TOSTER)
library(eyetrackingR)
library(wesanderson)
library(gghalves)
library(car)
library(multilevelTools)
library(JWileymisc)
library(broom.mixed)
library(papaja)
library(effectsize)
source("compute_iccs.R")
source("common.R")

theme_set(theme_cowplot())

knitr::opts_chunk$set(cache = FALSE, warn = FALSE,warning=FALSE, message = FALSE)
```

## Load data

```{r}
data_file_path <- here::here("..","..","data","processed_data","CATegories_exp2_processed_data_anonymized.csv")

d <- read_csv(data_file_path)

## add general category properties from typicality dataset
## typicality
animal_rating_names <- read.csv(here::here("..","..","data","processed_data","animal_ratings_stimuli_full.csv"))
animal_stims <- unique(c(unique(d$left_image),unique(d$right_image)))
typicality <- read.csv(here::here("..","..","data","processed_data","typicality_animals_summarized.csv")) %>%
  mutate(item_name=str_remove(animal_name,pattern=" ")) %>%
  left_join(animal_rating_names) %>%
  mutate(image_name_resized = str_replace(image_experiment_name,".jpg","")) %>%
  filter(image_name_resized %in% animal_stims)

#read in demographics
demographics <- read.csv(here::here("..","..","data","processed_data","CATegories_exp2_deidentified_demographics.csv"))

d <- d %>%
  left_join(typicality %>% select(image_name_resized,category,typicality_subjective),by=c("target_image" = "image_name_resized")) %>%
  left_join(demographics)%>%
  rename(typicality_condition=typicality_subjective)%>%
  filter(395<age & age<577) #filter out children outside of the age bounds (older than 13 months and younger than 19 months)
```

## Useable trial summary

In order for a trial to be included, participants must contribute at least 50% looking during the windows of interest when computing baseline-corrected proportion target looking: the critical window (300 ms - 2800 ms relative to target word onset) and the baseline window (-2000 ms - 0 ms relative to target word onset).

```{r}
critical_window <- c(300,2800)
baseline_window <- c(-2000,0)

summarize_subj_useable_trials_critical_window <- d %>%
  filter(corrected_time_centered>=critical_window[1]&corrected_time_centered<=critical_window[2]) %>%
  group_by(sub_num,age,age_mo, child_gender, session,trial_order,trial_number,target_image,target_typicality_z,condition) %>%
  summarize(
    length_critical_window=n(),
    useable_frames_critical_window=sum(!is.na(accuracy_transformed)),
    percent_useable_critical_window=useable_frames_critical_window/length_critical_window,
    useable_critical_window=ifelse(percent_useable_critical_window>=0.5,1,0), #useable if at least 50% looking
    mean_target_looking_critical=mean(accuracy_transformed,na.rm=TRUE)
  )

summarize_subj_useable_trials_baseline_window <- d %>%
  filter(corrected_time_centered>=baseline_window[1] & corrected_time_centered<=baseline_window[2]) %>%
  group_by(sub_num, session,age,age_mo, child_gender, trial_order,trial_number,target_image,target_typicality_z,condition) %>%
  summarize(
    length_baseline_window=n(),
    useable_frames_baseline_window=sum(!is.na(accuracy_transformed)),
    percent_useable_baseline_window=useable_frames_baseline_window/length_baseline_window,
    useable_baseline_window=ifelse(percent_useable_baseline_window>=0.5,1,0), #useable if at least 50% looking
    mean_target_looking_baseline=mean(accuracy_transformed,na.rm=TRUE)
  )

#overall useable trials
summarize_subj_useable_trials <- summarize_subj_useable_trials_critical_window %>%
  left_join(summarize_subj_useable_trials_baseline_window) %>%
  mutate(
    useable_window = ifelse(useable_baseline_window==1&useable_critical_window==1,1,0),
    corrected_target_looking = mean_target_looking_critical - mean_target_looking_baseline
  )
  

summarize_useable_trials <- summarize_subj_useable_trials %>%
  group_by(sub_num, age, child_gender, session,trial_order) %>%
  summarize(
    num_useable_trials=sum(useable_window),
    num_useable_trials_critical_window = sum(useable_critical_window)
  )

#total trials
summarize_subj_trials <- summarize_useable_trials %>%
  ungroup() %>%
  group_by(sub_num) %>%
  summarize(
    session_num = n(),
    total_trials = sum(num_useable_trials),
    total_trials_critical_window = sum(num_useable_trials_critical_window),
    exclude_participant = ifelse(total_trials<24,1,0),
    exclude_participant_critical = ifelse(total_trials_critical_window<24,1,0)
  )

#average trials contributed
mean(summarize_subj_trials$total_trials)

#participants to exclude based on data contribution
sum(summarize_subj_trials$exclude_participant)

#join with main data frame
summarize_useable_trials <- summarize_useable_trials %>%
  left_join(summarize_subj_trials)
d <- d %>%
  left_join(summarize_useable_trials) %>%
  left_join(summarize_subj_useable_trials)

summarize_useable_trials_wide <- summarize_useable_trials %>%
  ungroup() %>%
  select(sub_num,session_num,total_trials,exclude_participant,session,num_useable_trials) %>%
  group_by(sub_num,session_num,total_trials,exclude_participant) %>%
  pivot_wider(
    names_from = "session",
    names_prefix = "num_trials_session_",
    values_from = "num_useable_trials"
  )

#write out useable trial summary
write_csv(summarize_useable_trials_wide,here::here("..","..","data","processed_data","CATegories_exp2_useable_trial_summary.csv"))
```

Overall, among the trials contributed by the `r length(unique(summarize_useable_trials$sub_num))` participants, `r round(mean(summarize_subj_useable_trials$useable_window),3)*100`% of trials contained sufficient looking to meet our trial-level inclusion criteria (at least 50% looking during both the baseline window and the critical window). `r sum(summarize_subj_trials$exclude_participant==0)` of the `r length(unique(summarize_useable_trials$sub_num))` participants contributed sufficient looking data on at least half of the experimental trials (overall M = `r round(mean(summarize_subj_trials$total_trials),1)`)

## Summarize participant information

```{r}
#summarize subj info
subj_info_multisession <- d %>%
  distinct(sub_num, age,months,age_mo,child_gender,trial_order) %>%
  mutate(
    age_mo_c = age_mo - mean(age_mo),
    age_c = age - mean(age)
  )

subj_info <- d %>%
  distinct(sub_num,child_gender) %>%
  summarize(
    N = n(),
    N_female = sum(child_gender=="f")
  )

overall_subj_info <- subj_info_multisession %>%
  summarize(
    N = length(unique(sub_num)),
    sessions = n(),
    mean_age = mean(age_mo),
    min_age = min(age),
    max_age = max(age),
    sd_age = sd(age_mo)
  ) %>%
  left_join(subj_info)
  
overall_subj_info %>%
  knitr::kable()

# subjects with usable trial data only

subj_info_multisession_usable_trials <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num, age,months,age_mo,child_gender,trial_order) %>%
  mutate(
    age_mo_c = age_mo - mean(age_mo),
    age_c = age - mean(age)
  )

subj_info_usable_trials <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num,child_gender) %>%
  summarize(
    N = n(),
    N_female = sum(child_gender=="f")
  )

overall_subj_info_usable_trials <- subj_info_multisession_usable_trials %>%
  summarize(
    N = length(unique(sub_num)),
    sessions = n(),
    mean_age = mean(age_mo),
    min_age = min(age),
    max_age = max(age),
    sd_age = sd(age_mo)
  ) %>%
  left_join(subj_info_usable_trials)
  
overall_subj_info_usable_trials %>%
  knitr::kable()

```

= \## Demographics of final usable sample

```{r}
demographics_summary <- d %>%
  filter(exclude_participant == 0) %>%
  filter(useable_window == 1) %>%
  distinct(sub_num,demographic__us_race_ethnicity_identification,demographic__education_level,demographic__annual_income,demographic__country,demographic__state,demographic__density)


race_ethnicity <- demographics_summary%>%
  group_by(demographic__us_race_ethnicity_identification)%>%
  summarize(
    N = n()
  )

#quick visualiztion
ggplot(demographics_summary,aes(demographic__us_race_ethnicity_identification)) +
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90))

income <- demographics_summary %>%
  group_by(demographic__annual_income)%>%
  summarize(
    N = n()
  )
sum(income$N)
19/87

#quick visualiztion
ggplot(demographics_summary,aes(demographic__annual_income)) +
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90))

education <- demographics_summary %>%
  group_by(demographic__education_level)%>%
  summarize(
    N = n()
  )

states <- demographics_summary %>%
  summarize(
    N = length(unique(demographic__state)),
  )

ggplot(demographics_summary,aes(demographic__state)) +
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90))

population_density <- demographics_summary %>%
  group_by(demographic__density) %>%
  summarize(
    N = n()
  )

```

### Overall

Here, we summarize each participants' average accuracy during the critical window and average baseline-corrected proportion target looking.

```{r}
# critical window only
## trial-level
trial_critical_window_accuracy <- d %>%
  filter(exclude_participant_critical==0) %>%
  filter(useable_critical_window==1) %>%
  filter(corrected_time_centered>=300&corrected_time_centered<=2800) %>%
  group_by(sub_num, age,age_mo, child_gender, trial_order,trial_number,category,target_image,target_typicality_z,condition) %>%
  summarize(mean_accuracy=mean(accuracy_transformed,na.rm=TRUE))
## average
avg_critical_window_accuracy <- trial_critical_window_accuracy %>%
  ungroup() %>%
  group_by(sub_num, child_gender) %>%
  summarize(N=n(),
            mean_age = mean(age),
            mean_age_mo = mean(age_mo),
            accuracy=mean(mean_accuracy,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(mean_accuracy,na.rm=T)/sqrt(N),
            lower_ci=accuracy-ci,
            upper_ci=accuracy+ci)

#baseline-corrected target looking
## trial-level
trial_corrected_accuracy <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num,session, age,age_mo, child_gender, trial_order,trial_number,category,target_image,target_typicality_z,distractor_typicality_z,target_parent_typicality_rating,distractor_parent_typicality_rating,target_parent_typicality_rating_z,distractor_parent_typicality_rating_z,target_parent_typicality_by_category_z,distractor_parent_typicality_by_category_z, condition,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking)

## average
avg_corrected_target_looking <- trial_corrected_accuracy  %>%
  group_by(sub_num, child_gender) %>%
  summarize(N=n(),
            mean_age = mean(age),
            mean_age_mo = mean(age_mo),
            average_corrected_target_looking=mean(corrected_target_looking,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(corrected_target_looking,na.rm=T)/sqrt(N),
            lower_ci=average_corrected_target_looking-ci,
            upper_ci=average_corrected_target_looking+ci)

```

#### Compute ICCs

```{r}
df_for_icc <- trial_corrected_accuracy %>%
  #some light renaming to use Peekbank icc function
  mutate(
    administration_id = sub_num
  ) %>%
  unite("trial_id", administration_id, trial_number,remove=F) %>%
  mutate(
    target_label=target_image
  )

icc_participants <- df_for_icc %>%
  get_icc(object = "administration",column="corrected_target_looking")
icc_participants_typical <- df_for_icc %>%
  filter(condition=="typical") %>%
  get_icc(object = "administration",column="corrected_target_looking")
icc_participants_atypical <- df_for_icc %>%
  filter(condition=="atypical") %>%
  get_icc(object = "administration",column="corrected_target_looking")
icc_stimuli <- df_for_icc %>%
  get_icc(object = "stimulus",column="corrected_target_looking")
icc_stimuli_typical <- df_for_icc %>%
  filter(condition=="typical") %>%
  get_icc(object = "stimulus",column="corrected_target_looking")
icc_stimuli_atypical <- df_for_icc %>%
  filter(condition=="atypical") %>%
  get_icc(object = "stimulus",column="corrected_target_looking")

df_for_icc %>%
  get_icc(object = "stimulus",column="mean_target_looking_baseline")
df_for_icc %>%
  get_icc(object = "stimulus",column="mean_target_looking_critical")
df_for_icc %>%
  get_icc(object = "administration",column="mean_target_looking_critical")
df_for_icc %>%
  filter(condition=="atypical") %>%
  get_icc(object = "administration",column="mean_target_looking_critical")
```

### By Typicality Condition

Here, we summarize each participants' average accuracy during the critical window and average baseline-corrected proportion target looking.

```{r}
# critical window only
avg_critical_window_accuracy_by_typicality <- d %>%
  filter(exclude_participant_critical==0) %>%
  filter(useable_critical_window==1) %>%
  filter(corrected_time_centered>=300&corrected_time_centered<=2800) %>%
  group_by(sub_num, age,age_mo, child_gender, trial_order,trial_number,target_image,target_typicality_z,condition) %>%
  summarize(mean_accuracy=mean(accuracy_transformed,na.rm=TRUE)) %>%
  ungroup() %>%
  group_by(sub_num, child_gender,condition) %>%
  summarize(N=n(),
            mean_age = mean(age),
            mean_age_mo = mean(age_mo),
            accuracy=mean(mean_accuracy,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(mean_accuracy,na.rm=T)/sqrt(N),
            lower_ci=accuracy-ci,
            upper_ci=accuracy+ci)

#baseline-corrected target looking
avg_corrected_target_looking_by_typicality <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num, age,age_mo, child_gender, trial_order,trial_number,target_image,target_typicality_z,condition,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking) %>%
  group_by(sub_num, child_gender,condition) %>%
  summarize(N=n(),
            mean_age = mean(age),
            mean_age_mo = mean(age_mo),
            average_corrected_target_looking=mean(corrected_target_looking,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(corrected_target_looking,na.rm=T)/sqrt(N),
            se=sd(corrected_target_looking,na.rm=T)/sqrt(N),
            lower_ci=average_corrected_target_looking-ci,
            upper_ci=average_corrected_target_looking+ci,
            lower_se=average_corrected_target_looking-se,
            upper_se=average_corrected_target_looking+se)

#baseline-corrected target looking summarized overall
overall_corrected_target_looking_by_typicality <- avg_corrected_target_looking_by_typicality %>%
  group_by(condition) %>%
  summarize(N=n(),
            corrected_target_looking=mean(average_corrected_target_looking,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(average_corrected_target_looking,na.rm=T)/sqrt(N),
            lower_ci=corrected_target_looking-ci,
            upper_ci=corrected_target_looking+ci)

#avg typicality baseline-corrected target looking
avg_corrected_target_looking_category <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num, months,age_mo,child_gender, trial_order,typicality_condition,trial_number,category,target_image,target_typicality_z,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking) %>%
  group_by(sub_num, child_gender, typicality_condition,category) %>%
  summarize(N=n(),
            average_corrected_target_looking=mean(corrected_target_looking,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(corrected_target_looking,na.rm=T)/sqrt(N),
            lower_ci=average_corrected_target_looking-ci,
            upper_ci=average_corrected_target_looking+ci)

```

## Models

## Aim 1

### 1.1

```{r}
avg_corrected_target_looking_by_typicality <- avg_corrected_target_looking_by_typicality %>%
  mutate(
    typicality_condition_c = case_when(
      condition == "atypical" ~ -0.5,
      condition == "typical" ~ 0.5,
      TRUE ~ NA_real_
    ),
    typicality_condition_typ = case_when(
      condition == "atypical" ~ -1,
      condition == "typical" ~ 0,
      TRUE ~ NA_real_
    ),
    typicality_condition_atyp = case_when(
      condition == "atypical" ~ 0,
      condition == "typical" ~ 1,
      TRUE ~ NA_real_
    ),
  )

m_1_1 <- lmer(average_corrected_target_looking ~ 1 + typicality_condition_c + (1|sub_num),data=avg_corrected_target_looking_by_typicality)

summary(m_1_1)
confint(m_1_1,method="Wald")

```

##### 1.1.1.

Yes, infants significantly recognized the target word.

##### 1.1.2

No significant effect of typicality

Equivalence test - can't reject equivalence test

```{r}
overall_condition_summary <- avg_corrected_target_looking_by_typicality %>%
  ungroup() %>%
  group_by(sub_num) %>%
  summarize(
    condition_diff = average_corrected_target_looking[condition=="typical"]-average_corrected_target_looking[condition=="atypical"]
  ) %>%
  ungroup() %>%
  summarize(
    N=n(),
    diff = mean(condition_diff),
    sd = sd(condition_diff)
  )

tsum_TOST(m1=overall_condition_summary$diff,sd1=overall_condition_summary$sd,n1=overall_condition_summary$N,eqb=0.25, eqbound_type = "SMD")
```

```{r}
#quick sanity check
#t-test in tost is equivalent to regular old paired t-test
# AND equivalent to lmer estimate of typicality effect
t.test(
  avg_corrected_target_looking_by_typicality$average_corrected_target_looking[avg_corrected_target_looking_by_typicality$condition=="typical"],
  avg_corrected_target_looking_by_typicality$average_corrected_target_looking[avg_corrected_target_looking_by_typicality$condition=="atypical"], 
  paired=T)
#effect size
cohens_d(avg_corrected_target_looking_by_typicality$average_corrected_target_looking[avg_corrected_target_looking_by_typicality$condition=="typical"],
         avg_corrected_target_looking_by_typicality$average_corrected_target_looking[avg_corrected_target_looking_by_typicality$condition=="atypical"],
         paired=T)
```

##### 1.1.3

```{r}
m_1_1_3_typ <- lmer(average_corrected_target_looking ~ 1 + typicality_condition_typ + (1|sub_num),data=avg_corrected_target_looking_by_typicality)

summary(m_1_1_3_typ)

confint(m_1_1_3_typ,method="Wald")
#effect size
cohens_d(avg_corrected_target_looking_by_typicality$average_corrected_target_looking[avg_corrected_target_looking_by_typicality$condition=="typical"])
```

Infants successfully recognize words in the typical condition.

```{r}
m_1_1_3_atyp <- lmer(average_corrected_target_looking ~ 1 + typicality_condition_atyp + (1|sub_num),data=avg_corrected_target_looking_by_typicality)

summary(m_1_1_3_atyp)

confint(m_1_1_3_atyp,method="Wald")

#effect size
cohens_d(avg_corrected_target_looking_by_typicality$average_corrected_target_looking[avg_corrected_target_looking_by_typicality$condition=="atypical"])
```

Infants successfully recognize words in the atypical condition.

### 1.2

```{r}
trial_corrected_accuracy <- trial_corrected_accuracy %>%
  mutate(
    typicality_condition_c = case_when(
      condition == "atypical" ~ -0.5,
      condition == "typical" ~ 0.5,
      TRUE ~ NA_real_
    ),
    typicality_condition_typ = case_when(
      condition == "atypical" ~ -1,
      condition == "typical" ~ 0,
      TRUE ~ NA_real_
    ),
    typicality_condition_atyp = case_when(
      condition == "atypical" ~ 0,
      condition == "typical" ~ 1,
      TRUE ~ NA_real_
    ),
  )

m_1_2 <- lmer(corrected_target_looking ~ 1 + typicality_condition_c + 
            (1 + typicality_condition_c||sub_num) +
            (1|category),
          data=trial_corrected_accuracy)
summary(m_1_2)

confint(m_1_2,method="Wald")
```

Centering on typical condition

```{r}
m_1_2_typ <- lmer(corrected_target_looking ~ 1 + typicality_condition_typ + 
            (1 + typicality_condition_typ||sub_num) +
            (1|category),
          data=trial_corrected_accuracy)
summary(m_1_2_typ)

confint(m_1_2_typ,method="Wald")
```

Centering on atypical condition

```{r}
m_1_2_atyp <- lmer(corrected_target_looking ~ 1 + typicality_condition_atyp + 
            (1 + typicality_condition_atyp||sub_num) +
            (1|category),
          data=trial_corrected_accuracy)
summary(m_1_2_atyp)

confint(m_1_2_atyp,method="Wald")
```

#### 1.3

##### Resampling

In order to plot participants' average proportion looking to the target across the trial, we smooth/ resample time. This is necessary when plotting the timecourses given the variable sampling rate in the data (otherwise the mean observations "jump around" due to varying contributing data composition at different time points).

```{r}
target_ms_per_frame=1000/15
#adapted from: https://github.com/langcog/peekds/blob/master/R/generate_aoi.R
resample_trial <- function(df_trial) {
  t_origin <- df_trial$corrected_time_centered
  data_origin <- df_trial$accuracy_transformed

  # create the new timestamps for resampling
  t_start <- min(t_origin) - (min(t_origin) %% target_ms_per_frame)
  t_resampled <- seq(from = t_start, to = max(t_origin),
                     by = target_ms_per_frame)

  # exchange strings values with integers for resampling
  # this step critical for interpolating missing vals quickly and correctly
  aoi_num <- data_origin %>%
    dplyr::recode(.missing = 2) #recode NA as 2
    
  # start resampling with approx
  aoi_resampled <- stats::approx(x = t_origin, y = aoi_num, xout = t_resampled,
                                 method = "constant", rule = 2,
                                 ties = "ordered")$y
  aoi_resampled_recoded <- aoi_resampled %>%
    dplyr::recode("0"="0","1"="1","2" = "missing") %>%
    as.numeric()

  # adding back the columns to match schema
  dplyr::tibble(corrected_time_centered = t_resampled,
                accuracy_transformed = aoi_resampled_recoded,
                sub_num_session_order_trial_number = df_trial$sub_num_session_order_trial_number[1],
                sub_num = df_trial$sub_num[1])
}

d_resampled <- d %>%
  dplyr::mutate(sub_num_session_order_trial_number = paste(.data$sub_num,.data$session,.data$trial_order,
                                           .data$trial_number, sep = "_")) %>%
      split(.$sub_num_session_order_trial_number) %>%
      purrr::map_df(resample_trial) %>%
      dplyr::arrange(.data$sub_num, .data$sub_num_session_order_trial_number)

d_info <- d %>%
  select(-corrected_time_centered,-accuracy_transformed) %>%
  distinct(sub_num, exclude_participant, useable_window, age,age_mo, child_gender, trial_order, condition, session,trial_order,trial_number,target_image,target_typicality_z)

d_resampled <- d_resampled %>%
  separate(sub_num_session_order_trial_number,into=c("exp_name","sub_number","session","trial_order","trial_number"),sep="_",remove=F) %>%
  mutate(session=as.numeric(session),trial_number=as.numeric(trial_number)) %>%
  left_join(d_info) %>%
  mutate(corrected_time_centered =round(corrected_time_centered,0))
```

##### Timecourse analysis - cluster-based permutation analysis

Next, we prepare the data for use with the eyetrackingR package

```{r}
d_eyetrackingr <- d_resampled %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  unite("unique_trial",trial_order,trial_number,sep="_",remove=FALSE) %>%
  mutate(
    target = case_when(
      is.na(accuracy_transformed) ~ NA,
      accuracy_transformed == 1 ~ TRUE,
      accuracy_transformed == 0 ~ FALSE,
    ),
    distractor = case_when(
      is.na(accuracy_transformed) ~ NA,
      accuracy_transformed == 0 ~ TRUE,
      accuracy_transformed == 1 ~ FALSE,
    ),
    trackloss = case_when(
      is.na(accuracy_transformed) ~ TRUE,
      TRUE ~ FALSE
    )
  ) %>%
  make_eyetrackingr_data(
    participant_column = "sub_num",
    trial_column = "unique_trial",
    time_column = "corrected_time_centered",
    trackloss_column = "trackloss",
    aoi_columns = c("target","distractor"),
    treat_non_aoi_looks_as_missing = TRUE
  )

#note that we analyze the entire timecourse here!
response_window <- subset_by_window(
  d_eyetrackingr,
  window_start_time = -2000,
  window_end_time = 4000,
  rezero=FALSE
)
summary_data_loss <- describe_data(response_window, 'target', 'sub_num')

response_time <- make_time_sequence_data(response_window,
                                  time_bin_size = 100, 
                                  predictor_columns = c("condition"),
                                  aois = "target",
                                  summarize_by = "sub_num" )

# visualize timecourse
plot(response_time, predictor_column = "condition") + 
  theme_light() +
  coord_cartesian(ylim = c(0,1))

#divergence analysis
# tb_analysis <- analyze_time_bins(data = response_time, predictor_column = "condition", test= 'boot_splines', within_subj = TRUE, bs_samples = 1000, alpha = .05/num_time_bins)
# plot(tb_analysis) + theme_light()
# summary(tb_analysis)

#bootstrapped cluster-based permutation analysis
n_samples <- 1000
threshold_t <- 2
df_timeclust <- make_time_cluster_data(response_time, 
                                      test= "t.test", paired=TRUE,
                                      predictor_column = "condition", 
                                      threshold = threshold_t) 
plot(df_timeclust) +  ylab("T-Statistic") + theme_light()
summary(df_timeclust)
clust_analysis <- analyze_time_clusters(df_timeclust, within_subj=TRUE, paired=TRUE,
                                        samples=n_samples)
plot(clust_analysis) + theme_light()
summary(clust_analysis)
```

What if we analyze just the critical window? (exploratory analysis)

```{r}
response_window <- subset_by_window(
  d_eyetrackingr,
  window_start_time = 300,
  window_end_time = 2800,
  rezero=FALSE
)
summary_data_loss <- describe_data(response_window, 'target', 'sub_num')

response_time <- make_time_sequence_data(response_window,
                                  time_bin_size = 100, 
                                  predictor_columns = c("condition"),
                                  aois = "target",
                                  summarize_by = "sub_num" )

# visualize timecourse
plot(response_time, predictor_column = "condition") + 
  theme_light() +
  coord_cartesian(ylim = c(0,1))

#divergence analysis
# tb_analysis <- analyze_time_bins(data = response_time, predictor_column = "condition", test= 'boot_splines', within_subj = TRUE, bs_samples = 1000, alpha = .05/num_time_bins)
# plot(tb_analysis) + theme_light()
# summary(tb_analysis)

#bootstrapped cluster-based permutation analysis
n_samples <- 1000
threshold_t <- 2
df_timeclust <- make_time_cluster_data(response_time, 
                                      test= "t.test", paired=TRUE,
                                      predictor_column = "condition", 
                                      threshold = threshold_t) 
plot(df_timeclust) +  ylab("T-Statistic") + theme_light()
summary(df_timeclust)
clust_analysis <- analyze_time_clusters(df_timeclust, within_subj=TRUE, paired=TRUE,
                                        samples=n_samples)
plot(clust_analysis) + theme_light()
summary(clust_analysis)
```

##### Timecourse Plot

Next, we plot the data. First we summarize the data in two steps: (1) summarize the data by subject for each time point, followed by (2) averaging looking for each time point across subjects.

```{r}
#summarizing within subject for each time point
summarize_subj <- d_resampled %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  group_by(sub_num, child_gender, corrected_time_centered) %>%
  summarize(N=n(),
            mean_age=mean(age),
            mean_age_mo=mean(age_mo),
            non_na_n = sum(!is.na(accuracy_transformed)), 
            mean_accuracy=mean(accuracy_transformed,na.rm=TRUE),
            ci=qt(0.975, non_na_n-1)*sd(accuracy_transformed,na.rm=T)/sqrt(non_na_n),
            lower_ci=mean_accuracy-ci,
            upper_ci=mean_accuracy+ci) %>%
  ungroup()

#summarizing across subjects for each time point
summarize_across_subj <- summarize_subj %>%
  group_by(corrected_time_centered) %>%
  dplyr::summarize(n=n(),
            accuracy=mean(mean_accuracy,na.rm=TRUE),
            sd_accuracy=sd(mean_accuracy,na.rm=TRUE),
            se_accuracy=sd_accuracy/sqrt(n))

ggplot(summarize_across_subj,aes(corrected_time_centered,accuracy))+
  xlim(-2000,4000)+
  geom_smooth(method="gam")+
  geom_errorbar(aes(ymin=accuracy-se_accuracy,ymax=accuracy+se_accuracy),width=0)+
  geom_point()+
  geom_vline(xintercept=0,size=1.5)+
  geom_hline(yintercept=0.5,size=1.2,linetype="dashed")+
  geom_vline(xintercept=300,linetype="dotted")+
  ylim(0.35,0.65)
ggsave(here::here("..","figures","overall_accuracy.png"))

```

### Timecourse by age

```{r}
summarize_across_subj_by_age <- summarize_subj %>%
  mutate(age_group=ifelse(mean_age_mo>16,"older than 16 months","younger than 16 months")) %>%
  group_by(age_group,corrected_time_centered) %>%
  dplyr::summarize(n=n(),
                   accuracy=mean(mean_accuracy,na.rm=TRUE),
                   sd_accuracy=sd(mean_accuracy,na.rm=TRUE),
                   se_accuracy=sd_accuracy/sqrt(n))
ggplot(summarize_across_subj_by_age,aes(corrected_time_centered,accuracy))+
  xlim(-2000,4000)+
  geom_smooth(method="gam")+
  geom_errorbar(aes(ymin=accuracy-se_accuracy,ymax=accuracy+se_accuracy),width=0)+
  geom_point()+
  geom_vline(xintercept=0,size=1.5)+
  geom_hline(yintercept=0.5,size=1.2,linetype="dashed")+
  geom_vline(xintercept=300,linetype="dotted")+
  facet_wrap(~age_group)
ggsave(here::here("..","figures","overall_accuracy_by_age.png"),width=12, height=9)
```

### Timecourse by condition

```{r}
summarize_subj_condition <- d_resampled %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  group_by(sub_num, child_gender, condition, corrected_time_centered) %>%
  summarize(
    mean_age=mean(age),
    mean_age_mo=mean(age_mo),
    mean_accuracy=mean(accuracy_transformed,na.rm=TRUE))

summarize_across_subj_cond <- summarize_subj_condition %>%
  group_by(condition,corrected_time_centered) %>%
  summarize(n=n(),
            accuracy=mean(mean_accuracy,na.rm=TRUE),
            sd_accuracy=sd(mean_accuracy,na.rm=TRUE),
            se_accuracy=sd_accuracy/sqrt(n))

num_subjects <- summarize_across_subj_cond %>%
  group_by()%>%
  summarize(max_subnum=max(n))

summarize_across_subj_cond<- summarize_subj_condition %>%
  group_by(condition,corrected_time_centered) %>%
  summarize(n=n(),
            accuracy=mean(mean_accuracy,na.rm=TRUE),
            sd_accuracy=sd(mean_accuracy,na.rm=TRUE),
            se_accuracy=sd_accuracy/sqrt(n))

#plot
pal <- wes_palette("Rushmore1", n=5)
timecourse_plot <- ggplot(summarize_across_subj_cond,aes(corrected_time_centered,accuracy,color=condition))+
  xlim(-2500,4000)+
  geom_rect(data = data.frame(xmin = 300,
                              xmax = 2800,
                              ymin = -Inf,
                              ymax = Inf),
            aes(x=NULL, y=NULL,xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax,color=NULL),
            fill = "grey", alpha = 0.2)+
  geom_rect(data = data.frame(xmin = -2000,
                              xmax = 0,
                              ymin = -Inf,
                              ymax = Inf),
            aes(x=NULL, y=NULL,xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax,color=NULL),
            fill = "grey", alpha = 0.2)+
  geom_errorbar(aes(ymin=accuracy-se_accuracy,ymax=accuracy+se_accuracy),width=0)+
  geom_point(alpha=0.5)+
  geom_smooth(data=summarize_subj_condition,aes(y=mean_accuracy),method="gam")+
  geom_vline(xintercept=0,size=1.5)+
  geom_hline(yintercept=0.5,size=1.2,linetype="dashed")+
  geom_vline(xintercept=300,linetype="dotted")+
  geom_vline(xintercept=2800,linetype="dotted")+
  geom_vline(xintercept=-2000,linetype="dotted")+
  geom_vline(xintercept=0,linetype="dotted")+
  theme(legend.position = c(0.75,0.15))+
  annotate("text",label="Critical Window",x=1550,y=0.9)+
  annotate("text",label="Baseline Window",x=-1000,y=0.9)+
  ylim(0,1)+
  xlim(-2000,4000)+
  scale_colour_manual(values=pal[c(3,4)])+
  ylab("Proportion Target Looking")+
  xlab("Time (centered on target word onset, in ms)")
ggsave(here::here("..","figures","typicality_accuracy.png"),width=10,height=6)
```

## Aim 2

### Change across age

```{r}
trial_corrected_accuracy <- trial_corrected_accuracy %>%
  left_join(subj_info_multisession)
  

m_2 <- lmer(corrected_target_looking ~ 1 + typicality_condition_c * age_mo_c + 
            (1 + typicality_condition_c|sub_num) +
            (1|category),
          data=trial_corrected_accuracy)

summary(m_2)

#save interim model object
# m_2_tidy <- m_2 %>%
#   summarize_mixed_effects_model()
```

In the trial-level linear mixed-effects model including age, typicality condition, and their interaction, we found a significant effect of age (`r apa_print(m_2)$estimate$age_mo_c`, `r apa_print(m_2)$statistic$age_mo_c`), suggesting that word recognition accuracy increased with age overall. There was no significant interaction between age and typicality (`r apa_print(m_2)$estimate$typicality_condition_c_age_mo_c`, `r apa_print(m_2)$statistic$typicality_condition_c_age_mo_c`), meaning that we found no evidence that the effect of typicality changed with age.

#### Exploratory Analysis: Controlling for Baseline rather than Baseline Correction in Aim 2


```{r}
#exploratory: controlling for baseline looking rather than modeling the difference
m <- lmer(mean_target_looking_critical ~ 1 + typicality_condition_c * age_mo_c + mean_target_looking_baseline +
            (1 + typicality_condition_c|sub_num) +
            (1|category),
          data=trial_corrected_accuracy)
summary(m)
```

### Visualizations

#### Accuracy across age

##### Critical Window Only

```{r}
ggplot(filter(avg_critical_window_accuracy,mean_age<700),aes(mean_age,accuracy))+
  geom_pointrange(aes(ymin=lower_ci,ymax=upper_ci), 
                  position=position_jitter(width=0.1),
                  width=0,
                  size=1.5) +
  geom_hline(yintercept=0.5,linetype="dashed")+
  geom_smooth(method="lm")+
  xlab("Age (in days)")+
  ylab("Proportion Target Looking\nduring the Critical Window")+
  ylim(0,1)
ggsave(here::here("..","figures","age_relationship_critical_window_accuracy.png"),width=7,height=6)
```

##### Baseline-corrected proportion target looking

```{r}
ggplot(avg_corrected_target_looking,aes(mean_age,average_corrected_target_looking))+
  geom_pointrange(aes(ymin=lower_ci,ymax=upper_ci),
                  position=position_jitter(width=0.1),
                  width=0,
                  size=1.5) +
  geom_hline(yintercept=0,linetype="dashed")+
  geom_smooth(method="lm")+
  xlab("Age (in months)")+
  ylab("Baseline-Corrected Proportion Target Looking")+
  ylim(-0.55,0.55)+
  scale_x_continuous(breaks=seq(12,18,1))
ggsave(here::here("..","figures","age_relationship_baseline_corrected_accuracy.png"),width=7,height=6)
```

#### Quick Visualization of the Typicalty Effect Across Age

```{r}
ggplot(avg_corrected_target_looking_by_typicality,aes(mean_age,average_corrected_target_looking,color=condition))+
  geom_point()+
  geom_smooth(method="lm")+
  geom_hline(yintercept=0,linetype="dashed")

ggplot(trial_critical_window_accuracy,aes(age,mean_accuracy,color=condition))+
  geom_point(alpha=0.1)+
  geom_smooth()
```

## Aim 3

To test whether individual differences in word recognition or typicality effects are predicted by differences in experiences with each exemplar.

```{r}
#subject details for aim 3 analysis (how many participants have survey data)
aim3_subject_info <- trial_corrected_accuracy %>%
  filter(!is.na(target_parent_typicality_rating_z)) %>%
  ungroup()%>%
  summarize(
    N = length(unique(sub_num)),
    mean_age = mean(age_c),
    sd_age = sd(age_c)
  )

aim3_subject_info%>%
  knitr::kable()

#model
m_3 <- lmer(corrected_target_looking ~ 1 + target_parent_typicality_rating_z + age_mo_c + (1|sub_num) + (1|category), trial_corrected_accuracy)

summary(m_3)

m_3_tidy <- m_3 %>%
  summarize_mixed_effects_model()
```

Caregiver report of exemplar typicality did not significantly predict infants’ baseline-corrected word recognition accuracy (`r apa_print(m_3)$estimate$target_parent_typicality_rating_z`, `r apa_print(m_3)$statistic$target_parent_typicality_rating_z`).  After controlling for the effect of parental report of typicality, age remained a significant predictor of infants’ word recognition (`r apa_print(m_3)$estimate$age_mo_c`, `r apa_print(m_3)$statistic$age_mo_c`). 

#### Exploratory analysis: Z-scored by category by participant experience ratings

```{r}

#model
m_3_1_2 <- lmer(corrected_target_looking ~ target_parent_typicality_by_category_z+age_mo_c+ (1|sub_num) + (1|category), trial_corrected_accuracy)

summary(m_3_1_2)

confint(m_3_1_2,method="Wald")
```

#### Exploratory analysis: Model accounting for distractor rating too

The outcome variable, average_corrected_target_looking accounts for baseline preferences for different images. We have typicality information for both the targets and the distractor. Does accounting for the saliency/experience with the distractor predict accuracy?

```{r}
#model
m_3_3 <- lmer(corrected_target_looking ~ target_parent_typicality_rating_z+distractor_parent_typicality_rating_z+age_mo_c+ (1|sub_num) + (1|category), trial_corrected_accuracy)

summary(m_3_3)

confint(m_3_3,method="Wald")
```

No, accounting for experience with the distractor does not explain infants' accuracy.

#### Visualization

```{r}
#by subject
ggplot(trial_corrected_accuracy,aes(target_parent_typicality_rating_z,corrected_target_looking))+
  geom_point(alpha=0.1)+
  geom_smooth(method = "lm")

ggplot(trial_corrected_accuracy,aes(target_parent_typicality_rating_z,corrected_target_looking))+
  geom_point(alpha=0.1)+
  geom_smooth(method = "lm")+
  facet_wrap(~condition)

#by category
ggplot(trial_corrected_accuracy,aes(target_parent_typicality_by_category_z,corrected_target_looking))+
  geom_point(alpha=0.1)+
  geom_smooth(method = "lm")+
  facet_wrap(~category)

ggplot(trial_corrected_accuracy,aes(target_parent_typicality_by_category_z,corrected_target_looking))+
  geom_point(alpha=0.1)+
  geom_smooth(method = "lm")+
  facet_wrap(~category+condition)

```

Parent's ratings of their infant's experience with each exemplar does not predict accuracy.

## Aim 4

We will conduct a series of analyses to determine whether our results hold across a variety of different analytic decisions

### 4.1. Window

##### Define alternative critical window

```{r}

critical_window_alternative <- c(300,1800)

summarize_subj_useable_trials_critical_window_alternative <- d %>%
  filter(corrected_time_centered>=critical_window_alternative[1]&corrected_time_centered<=critical_window_alternative[2]) %>%
  group_by(sub_num,age,age_mo, child_gender, session,trial_order,trial_number,target_image,target_typicality_z,condition) %>%
  summarize(
    length_critical_window_alternative=n(),
    useable_frames_critical_window_alternative=sum(!is.na(accuracy_transformed)),
    percent_useable_critical_window_alternative=useable_frames_critical_window_alternative/length_critical_window_alternative,
    useable_critical_window_alternative=ifelse(percent_useable_critical_window_alternative>=0.5,1,0), #useable if at least 50% looking
    mean_target_looking_critical_alternative=mean(accuracy_transformed,na.rm=TRUE)
  )

#overall useable trials
summarize_subj_useable_trials_alternative <- summarize_subj_useable_trials_critical_window_alternative %>%
  left_join(summarize_subj_useable_trials_baseline_window) %>%
  mutate(
    useable_window_alternative = ifelse(useable_baseline_window==1&useable_critical_window_alternative==1,1,0),
    corrected_target_looking_alternative = mean_target_looking_critical_alternative - mean_target_looking_baseline
  )
  

summarize_useable_trials_alternative <- summarize_subj_useable_trials_alternative %>%
  group_by(sub_num, age, child_gender, session,trial_order) %>%
  summarize(
    num_useable_trials_alternative=sum(useable_window_alternative),
    num_useable_trials_critical_window_alternative = sum(useable_critical_window_alternative)
  )

#total trials
summarize_subj_trials_alternative <- summarize_useable_trials_alternative %>%
  ungroup() %>%
  group_by(sub_num) %>%
  summarize(
    session_num_alternative = n(),
    total_trials_alternative = sum(num_useable_trials_alternative),
    total_trials_critical_window_alternative = sum(num_useable_trials_critical_window_alternative),
    exclude_participant_alternative = ifelse(total_trials_alternative<24,1,0),
    exclude_participant_critical_alternative = ifelse(total_trials_critical_window_alternative<24,1,0)
  )

#average trials contributed
mean(summarize_subj_trials_alternative$total_trials_alternative)

#participants to exclude based on data contribution
sum(summarize_subj_trials_alternative$exclude_participant_alternative)

#join with main data frame
summarize_useable_trials_alternative <- summarize_useable_trials_alternative %>%
  left_join(summarize_subj_trials_alternative)
d <- d %>%
  left_join(summarize_useable_trials_alternative) %>%
  left_join(summarize_subj_useable_trials_alternative)

summarize_useable_trials_wide_alternative <- summarize_useable_trials_alternative %>%
  ungroup() %>%
  select(sub_num,session_num_alternative,total_trials_alternative,exclude_participant_alternative,session,num_useable_trials_alternative) %>%
  group_by(sub_num,session_num_alternative,total_trials_alternative,exclude_participant_alternative) %>%
  pivot_wider(
    names_from = "session",
    names_prefix = "num_trials_session_alternative",
    values_from = "num_useable_trials_alternative"
  )
```

##### By Typicality Condition for alternative critical window

Here, we summarize each participants' average accuracy during the alternative critical window and average baseline-corrected proportion target looking.

```{r}
# critical window only
avg_critical_window_accuracy_by_typicality_alternative <- d %>%
  filter(exclude_participant_critical_alternative==0) %>%
  filter(useable_critical_window_alternative==1) %>%
  filter(corrected_time_centered>=300&corrected_time_centered<=1800) %>%
  group_by(sub_num, age,age_mo, child_gender, trial_order,trial_number,target_image,target_typicality_z,condition) %>%
  summarize(mean_accuracy_alternative=mean(accuracy_transformed,na.rm=TRUE)) %>%
  ungroup() %>%
  group_by(sub_num, child_gender,condition) %>%
  summarize(N=n(),
            mean_age = mean(age),
            mean_age_mo = mean(age_mo),
            accuracy=mean(mean_accuracy_alternative,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(mean_accuracy_alternative,na.rm=T)/sqrt(N),
            lower_ci=accuracy-ci,
            upper_ci=accuracy+ci)

#baseline-corrected target looking
avg_corrected_target_looking_by_typicality_alternative <- d %>%
  filter(exclude_participant_alternative==0) %>%
  filter(useable_window_alternative==1) %>%
  distinct(sub_num, age,age_mo, child_gender, trial_order,trial_number,target_image,target_typicality_z,condition,mean_target_looking_critical_alternative,mean_target_looking_baseline,corrected_target_looking_alternative) %>%
  group_by(sub_num, child_gender,age,age_mo,condition) %>%
  summarize(N=n(),
            average_corrected_target_looking_alternative=mean(corrected_target_looking_alternative,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(corrected_target_looking_alternative,na.rm=T)/sqrt(N),
            lower_ci_alternative=average_corrected_target_looking_alternative-ci,
            upper_ci_alternative=average_corrected_target_looking_alternative+ci)

#avg typicality baseline-corrected target looking
avg_corrected_target_looking_category_alternative <- d %>%
  filter(exclude_participant_alternative==0) %>%
  filter(useable_window_alternative==1) %>%
  distinct(sub_num, months,age_mo,child_gender, trial_order,typicality_condition,trial_number,category,target_image,target_typicality_z,mean_target_looking_critical_alternative,mean_target_looking_baseline,corrected_target_looking_alternative) %>%
  group_by(sub_num, age_mo,child_gender, trial_order,typicality_condition,category) %>%
  summarize(N=n(),
            average_corrected_target_looking_alternative=mean(corrected_target_looking_alternative,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(corrected_target_looking_alternative,na.rm=T)/sqrt(N),
            lower_ci_alternative=average_corrected_target_looking_alternative-ci,
            upper_ci_alternative=average_corrected_target_looking_alternative+ci)

#avg typicality baseline-corrected target looking
avg_corrected_target_looking_typicality_alternative <- d %>%
  filter(exclude_participant_alternative==0) %>%
  filter(useable_window_alternative==1) %>%
  distinct(sub_num, months,age_mo,child_gender, trial_order,typicality_condition,trial_number,target_image,target_typicality_z,mean_target_looking_critical_alternative,mean_target_looking_baseline,corrected_target_looking_alternative) %>%
  group_by(sub_num, age_mo,child_gender, trial_order,typicality_condition) %>%
  summarize(N=n(),
            average_corrected_target_looking_alternative=mean(corrected_target_looking_alternative,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(corrected_target_looking_alternative,na.rm=T)/sqrt(N),
            se=sd(corrected_target_looking_alternative,na.rm=T)/sqrt(N),
            lower_ci_alternative=average_corrected_target_looking_alternative-ci,
            upper_ci_alternative=average_corrected_target_looking_alternative+ci,
            lower_se_alternative=average_corrected_target_looking_alternative-se,
            upper_se_alternative=average_corrected_target_looking_alternative+se)

#baseline-corrected target looking
## trial-level
trial_corrected_accuracy_alternative <- d %>%
  filter(exclude_participant_alternative==0) %>%
  filter(useable_window_alternative==1) %>%
  distinct(sub_num,session, age,age_mo, child_gender, trial_order,trial_number,category,target_image,target_typicality_z,distractor_typicality_z,target_parent_typicality_rating,distractor_parent_typicality_rating,target_parent_typicality_rating_z,distractor_parent_typicality_rating_z,target_parent_typicality_by_category_z,distractor_parent_typicality_by_category_z, condition,mean_target_looking_critical_alternative,mean_target_looking_baseline,corrected_target_looking_alternative)
## average
avg_corrected_target_looking_alternative <- trial_corrected_accuracy_alternative  %>%
  group_by(sub_num, child_gender) %>%
  summarize(N=n(),
            average_corrected_target_looking_alternative=mean(corrected_target_looking_alternative,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(corrected_target_looking_alternative,na.rm=T)/sqrt(N),
            lower_ci=average_corrected_target_looking_alternative-ci,
            upper_ci=average_corrected_target_looking_alternative+ci)

```

##### 4.1.1.1

Does typicality influence target looking?

```{r}
avg_corrected_target_looking_by_typicality_alternative <- avg_corrected_target_looking_by_typicality_alternative %>%
  mutate(
    typicality_condition_c = case_when(
      condition == "atypical" ~ -0.5,
      condition == "typical" ~ 0.5,
      TRUE ~ NA_real_
    ),
    typicality_condition_typ = case_when(
      condition == "atypical" ~ -1,
      condition == "typical" ~ 0,
      TRUE ~ NA_real_
    ),
    typicality_condition_atyp = case_when(
      condition == "atypical" ~ 0,
      condition == "typical" ~ 1,
      TRUE ~ NA_real_
    ),
  )

m_4_1_1_1 <- lmer(average_corrected_target_looking_alternative ~ 1 + typicality_condition_c + (1|sub_num),data=avg_corrected_target_looking_by_typicality_alternative)

summary(m_4_1_1_1)
confint(m_4_1_1_1,method="Wald")
```

##### 4.1.1.1.2

No significant effect of typicality

Equivalence test - can't reject equivalence test

```{r}
overall_condition_summary_alternative <- avg_corrected_target_looking_by_typicality_alternative %>%
  group_by(sub_num) %>%
  summarize(
    condition_diff_alternative = average_corrected_target_looking_alternative[condition=="typical"]-average_corrected_target_looking_alternative[condition=="atypical"]
  ) %>%
  ungroup() %>%
  summarize(
    N=n(),
    diff = mean(condition_diff_alternative),
    sd = sd(condition_diff_alternative)
  )

tsum_TOST(m1=overall_condition_summary_alternative$diff,sd1=overall_condition_summary_alternative$sd,n1=overall_condition_summary_alternative$N,eqb=0.25, eqbound_type = "SMD")
```

##### 4.1.1.1.3

```{r}
m_1_1_3_typ_alternative <- lmer(average_corrected_target_looking_alternative ~ 1 + typicality_condition_typ + (1|sub_num),data=avg_corrected_target_looking_by_typicality_alternative)

summary(m_1_1_3_typ_alternative)

confint(m_1_1_3_typ_alternative,method="Wald")
```

Infants successfully recognize words in the typical condition.

```{r}
m_1_1_3_atyp_alternative <- lmer(average_corrected_target_looking_alternative ~ 1 + typicality_condition_atyp + (1|sub_num),data=avg_corrected_target_looking_by_typicality_alternative)

summary(m_1_1_3_atyp_alternative)

confint(m_1_1_3_atyp_alternative,method="Wald")
```

Infants successfully recognize words in the atypical condition.

### 4.1.1.2

Trial level typicality effects

```{r}
trial_corrected_accuracy_alternative <- trial_corrected_accuracy_alternative %>%
  mutate(
    typicality_condition_c = case_when(
      condition == "atypical" ~ -0.5,
      condition == "typical" ~ 0.5,
      TRUE ~ NA_real_
    ),
    typicality_condition_typ = case_when(
      condition == "atypical" ~ -1,
      condition == "typical" ~ 0,
      TRUE ~ NA_real_
    ),
    typicality_condition_atyp = case_when(
      condition == "atypical" ~ 0,
      condition == "typical" ~ 1,
      TRUE ~ NA_real_
    ),
  )

m_4_1_1_2 <- lmer(corrected_target_looking_alternative ~ 1 + typicality_condition_c + 
            (1 + typicality_condition_c||sub_num) +
            (1|category),
          data=trial_corrected_accuracy_alternative)
summary(m_4_1_1_2)

confint(m_4_1_1_2,method="Wald")
```

##### 4.1.2

Aim 2 with alternative time window

###### Change across age

```{r}
trial_corrected_accuracy_alternative <- trial_corrected_accuracy_alternative %>%
  left_join(subj_info_multisession)
  

m_4_1_2 <- lmer(corrected_target_looking_alternative ~ 1 + typicality_condition_c * age_mo_c + 
            (1 + typicality_condition_c|sub_num) +
            (1|category),
          data=trial_corrected_accuracy_alternative)
summary(m_4_1_2)

confint(m_4_1_2,method="Wald")
```

Age is still a significant predictor when we use a smaller critical window. There is no age by typicality condition interaction.

##### 4.1.3

Aim 3: test whether individual differences in word recognition or typicality effects are predicted by differences in experiences with each exemplar using the alternative critical window

```{r}
#model
m_4_1_3 <- lmer(corrected_target_looking_alternative ~ 1 + target_parent_typicality_rating_z + age_mo_c + (1|sub_num) + (1|category), trial_corrected_accuracy_alternative)

summary(m_4_1_3)

m_4_1_3_tidy <- m_4_1_3 %>%
  summarize_mixed_effects_model()
```

Caregiver report of exemplar typicality did not significantly predict infants’ baseline-corrected word recognition accuracy (`r apa_print(m_4_1_3)$estimate$target_parent_typicality_rating_z`, `r apa_print(m_4_1_3)$statistic$target_parent_typicality_rating_z`).  After controlling for the effect of parental report of typicality, age remained a significant predictor of infants’ word recognition (`r apa_print(m_4_1_3)$estimate$age_mo_c`, `r apa_print(m_4_1_3)$statistic$age_mo_c`). 

### 4.2 excluding unknown words

We registered using CDI responses as a way to remove unknown words; however we did not administer the CDI. Thus, we are not including this analysis since it would require an arbitrary cutoff for word recognition as a proxy for understanding a word (i.e., what is the difference between 50% accuracy and 50.01% accuracy)

### 4.3 Reaction time as the dependent measure

We will fit models analogous to those in 1.1 and 1.2 using reaction time as our primary dependent measure rather than accuracy

### Load RT (computed using compute_RT.R & rt_helper.R)

```{r}
rt_path <- here::here("..","..","data","processed_data","CATegories_exp2_RT_by_trial.csv")
d_rt <- read_csv(rt_path)

d_trial_level <- d %>%
  distinct(sub_num,session, trial_number,condition, age, age_mo, target_image, child_gender,category)

d_rt<- d_trial_level %>%
  left_join(d_rt)

#d_rt<- trial_corrected_accuracy %>%
 # left_join(d_rt)

#participants must contribute 4 typical and 4 atypical trials to be included in analysis
d_rt_subj_summary <- d_rt %>%
  #filter(shift_type == "D-T")%>%
  group_by(sub_num, condition,shift_type) %>%
  summarize(
    trials = n(),
    useable_trials=ifelse(trials>=4,1,0)
  )

#add exclusionary criteria to DF
d_rt <- d_rt %>%
  left_join(d_rt_subj_summary)
```

### Visualization of RTs

```{r}
hist(filter(d_rt, shift_type=="D-T")$shift_start_rt)
```

The data are right skewed, which is common for RTs. We will use log transformations in the subsequent models to account for the distribution of the data.

### Models

#### 4.3.1 Subject-level RT

```{r}
avg_subj_RT <- d_rt %>%
  filter(shift_type=="D-T")%>%
  filter(useable_trials=="1")%>%
  group_by(sub_num, child_gender,condition) %>%
  summarize(N=n(),
            average_RT=mean(rt,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(rt,na.rm=T)/sqrt(N),
            lower_ci=average_RT-ci,
            upper_ci=average_RT+ci)


avg_subj_RT <- avg_subj_RT %>%
  mutate(
    typicality_condition_c = case_when(
      condition == "atypical" ~ -0.5,
      condition == "typical" ~ 0.5,
      TRUE ~ NA_real_
    ),
    typicality_condition_typ = case_when(
      condition == "atypical" ~ -1,
      condition == "typical" ~ 0,
      TRUE ~ NA_real_
    ),
    typicality_condition_atyp = case_when(
      condition == "atypical" ~ 0,
      condition == "typical" ~ 1,
      TRUE ~ NA_real_
    ),
  )

m_4_1 <- lmer(log(average_RT) ~ 1 + typicality_condition_c + (1|sub_num),data=avg_subj_RT)

summary(m_4_1)
confint(m_4_1,method="Wald")
```

There is no significant typicality effect.

#### 4.3.2 Trial level RT

```{r}
trial_rt <- d_rt %>%
  filter(shift_type=="D-T")%>%
  filter(useable_trials=="1") %>%
  mutate(
    typicality_condition_c = case_when(
      condition == "atypical" ~ -0.5,
      condition == "typical" ~ 0.5,
      TRUE ~ NA_real_
    ),
    typicality_condition_typ = case_when(
      condition == "atypical" ~ -1,
      condition == "typical" ~ 0,
      TRUE ~ NA_real_
    ),
    typicality_condition_atyp = case_when(
      condition == "atypical" ~ 0,
      condition == "typical" ~ 1,
      TRUE ~ NA_real_
    ),
  )

m_4_2 <- lmer(log(rt) ~ 1 + typicality_condition_c + 
            (1+ typicality_condition_c||sub_num) +
            (1|category),
          data=trial_rt)

summary(m_4_2)
confint(m_4_2,method="Wald")
```

### 4.3 Aim 3 models with RT as the outcome

Does experience with exemplars predict reaction time?

```{r}
parent_typicality_rt <- parent_typicality_z %>%
  #filter(exclude_participant==0) %>%
  #filter(useable_window==1) %>%
  distinct(sub_num,months,age,child_gender, trial_order,trial_number,category,target_image,target_typicality_z,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking,target_parent_typicality_z,distractor_parent_typicality_z,target_image,target_parent_typicality_rating,distractor_parent_typicality_rating)

trial_rt_parent <- left_join(trial_rt, parent_typicality_rt)  
  
trial_rt_parent <- trial_rt_parent%>%
  filter(shift_type == "D-T") %>%
  filter(useable_trials == "1")%>%
  mutate(
    age_mo_c = age_mo - mean(age_mo),
    age_c = age - mean(age)
  )

##subject details for aim 3 analysis with RT
rt_survey_subject_info <- parent_typicality_rt %>%
  ungroup()%>%
  summarize(
    N = length(unique(sub_num)),
    mean_age = mean(age),
    sd_age = sd(age)
  )

rt_survey_subject_info%>%
  knitr::kable()

#model
m_4_3 <- lmer(log(rt) ~ target_parent_typicality_z+age_c+(target_parent_typicality_z|sub_num) + (1|category), trial_rt_parent)

summary(m_4_3)

confint(m_4_3,method="Wald")

```

Parent report of typicality does not predict RT.

### 4.4 Do effects interact with test session?

We will fit models analogous to those in 1.1 and 1.2 including an interaction with test session

#### 4.4.1.1

```{r}

#baseline-corrected target looking by session
avg_corrected_target_looking_by_typicality_session <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num, age,age_mo, child_gender, trial_order,trial_number,target_image,target_typicality_z,condition,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking,session) %>%
  group_by(sub_num, child_gender,age,age_mo,condition, session) %>%
  summarize(N=n(),
            average_corrected_target_looking=mean(corrected_target_looking,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(corrected_target_looking,na.rm=T)/sqrt(N),
            lower_ci=average_corrected_target_looking-ci,
            upper_ci=average_corrected_target_looking+ci)


avg_corrected_target_looking_by_typicality_session <- avg_corrected_target_looking_by_typicality_session %>%
  mutate(
    typicality_condition_c = case_when(
      condition == "atypical" ~ -0.5,
      condition == "typical" ~ 0.5,
      TRUE ~ NA_real_
    ),
    typicality_condition_typ = case_when(
      condition == "atypical" ~ -1,
      condition == "typical" ~ 0,
      TRUE ~ NA_real_
    ),
    typicality_condition_atyp = case_when(
      condition == "atypical" ~ 0,
      condition == "typical" ~ 1,
      TRUE ~ NA_real_
    ),    
    session_c = session - 1.5
  )

m_4_4_1_1 <- lmer(average_corrected_target_looking ~ 1 + typicality_condition_c*session_c + (1|sub_num),data=avg_corrected_target_looking_by_typicality_session)

summary(m_4_4_1_1)
confint(m_4_4_1_1,method="Wald")
```

##### 4.4.1.1

No significant interactions with test session

##### 4.4.1.1.3

```{r}
m_4_4_1_1_3_typ <- lmer(average_corrected_target_looking ~ 1 + typicality_condition_typ*session_c + (1|sub_num),data=avg_corrected_target_looking_by_typicality_session)

summary(m_4_4_1_1_3_typ)

confint(m_4_4_1_1_3_typ,method="Wald")
```

Infants successfully recognize words in the typical condition.

```{r}
m_4_4_1_1_3_atyp <- lmer(average_corrected_target_looking ~ 1 + typicality_condition_atyp*session_c + (1|sub_num),data=avg_corrected_target_looking_by_typicality_session)

summary(m_4_4_1_1_3_atyp)

confint(m_4_4_1_1_3_atyp,method="Wald")
```

For an average session, infants recognition in the atypical condition is only marginally significantly above chance.

#### 4.4.1.2

```{r}
#baseline-corrected target looking
## trial-level
trial_corrected_accuracy_session <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num,session, age,age_mo, child_gender, trial_order,trial_number,category,target_image,target_typicality_z, condition,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking)


trial_corrected_accuracy_session <- trial_corrected_accuracy_session %>%
  mutate(
    typicality_condition_c = case_when(
      condition == "atypical" ~ -0.5,
      condition == "typical" ~ 0.5,
      TRUE ~ NA_real_
    ),
    typicality_condition_typ = case_when(
      condition == "atypical" ~ -1,
      condition == "typical" ~ 0,
      TRUE ~ NA_real_
    ),
    typicality_condition_atyp = case_when(
      condition == "atypical" ~ 0,
      condition == "typical" ~ 1,
      TRUE ~ NA_real_
    ),
    session_c = session - 1.5
  )


m_4_4_1_2 <- lmer(corrected_target_looking ~ 1 + typicality_condition_c*session_c + 
            (1 + typicality_condition_c||sub_num) +
            (1|category),
          data=trial_corrected_accuracy_session)
summary(m_4_4_1_2)
```

# Exploratory analyses:

## Ex1. typicality as a likert scale

We intentionally selected items at the end of a typicality scale from a set of adult-normed images. We categorized each image as typical or atypical based on adults ratings, however, we also have the origninal normed values. Does typicality influence accuracy when typicality is a continuum rather than a dichotomous variable.

### By Continuous typicality

(only possible to fit model on trial level)

```{r}

m_Ex1_2 <- lmer(corrected_target_looking ~ 1 + target_typicality_z + 
            (1 +target_typicality_z|sub_num)+
              (1|category),
          data=trial_corrected_accuracy)
summary(m_Ex1_2)

confint(m_Ex1_2,method="Wald")

```

Quick plot

```{r}
ggplot(trial_corrected_accuracy,aes(target_typicality_z,corrected_target_looking))+
  geom_point(aes(color=condition))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_smooth(method="lm")

ggplot(trial_corrected_accuracy,aes(target_typicality_z,corrected_target_looking))+
  geom_point(aes(color=condition))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_smooth(method="lm")+
  facet_wrap(~category)
```


##Ex2. Does typicality interact with category? Infants' processing for some categories may be better than other categories. Are infants better at processing typical category members for categories that are more accurate?

```{r}
#contrast coding:
trial_corrected_accuracy <- trial_corrected_accuracy %>%
  mutate(
    category_c1 = case_when(
      category == "bird" ~ 1,
      category == "cat" ~ 0,
      category == "dog" ~ 0,
      category == "fish" ~ 0,
      TRUE ~ NA_real_
    ),
    category_c2 = case_when(
      category == "bird" ~ 0,
      category == "cat" ~ 1,
      category == "dog" ~ 0,
      category == "fish" ~ 0,
      TRUE ~ NA_real_
    ),
    category_c3 = case_when(
      category == "bird" ~ 0,
      category == "cat" ~ 0,
      category == "dog" ~ 0,
      category == "fish" ~ 1,
      TRUE ~ NA_real_
    )
  )

##linear contrasts=
trial_corrected_accuracy <- trial_corrected_accuracy %>%
  mutate(
    category_ordered=factor(category,order=T,levels=c("dog","fish","bird","cat"))
  )


m_Ex2_1 <- lmer(corrected_target_looking ~ typicality_condition_c*category_ordered+
            (typicality_condition_c*category_ordered|sub_num),control=lmerControl(optCtrl=list(maxfun=50000),optimizer = "bobyqa"),
          data=trial_corrected_accuracy)

m_Ex2_1_c <- lmer(corrected_target_looking ~ typicality_condition_c+category_ordered+
            (typicality_condition_c+category_ordered||sub_num),control=lmerControl(optCtrl=list(maxfun=50000),optimizer = "bobyqa"),
          data=trial_corrected_accuracy)

anova(m_Ex2_1_c,m_Ex2_1)

summary(m_Ex2_1)

confint(m_Ex2_1,method="Wald")

```

The omnibus test was not significantly different from tjhe model without the interaction terms. Therefore, we did not follow up with

## Ex3. Does a typicality exert more of an effect on processing when the categories tested are more similar?

There are some categories that are more visually/categorically similar than other categories (i.e., cats and dogs vs. dogs and fish). Is there an effect of typicality when there is more category similarity?

```{r}
trial_corrected_accuracy_category <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num,session, age,age_mo, child_gender, trial_order,trial_number,category,left_image,right_image,target_image,target_typicality_z, condition,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking)%>%
  filter(category=="cat"|category=="dog")

trial_corrected_accuracy_category <- trial_corrected_accuracy_category%>%
  mutate(
    distractor_image=ifelse(target_image==right_image,left_image,
                           ifelse(target_image==left_image,right_image,NA))
  )
trial_corrected_accuracy_category <- trial_corrected_accuracy_category %>%
  filter(distractor_image=="afghanhound_600x600"|
           distractor_image=="arabianmau_600x600"|
           distractor_image=="chartreux_600x600"|
           distractor_image=="cornishrex_600x600"|
           distractor_image=="germanshepherd_600x600"|
           distractor_image=="goldenretriever_600x600"|
           distractor_image=="sheepdog_600x600"|
           distractor_image=="sphynx_600x600"
           )%>%
  mutate(
    typicality_condition_c = case_when(
      condition == "atypical" ~ -0.5,
      condition == "typical" ~ 0.5,
      TRUE ~ NA_real_
    ),
    typicality_condition_typ = case_when(
      condition == "atypical" ~ -1,
      condition == "typical" ~ 0,
      TRUE ~ NA_real_
    ),
    typicality_condition_atyp = case_when(
      condition == "atypical" ~ 0,
      condition == "typical" ~ 1,
      TRUE ~ NA_real_
    ),
  )

m_Ex3_1 <- lmer(corrected_target_looking ~ 1 + typicality_condition_c + 
            (1 + typicality_condition_c|sub_num) +
            (1|category),
          data=trial_corrected_accuracy_category)

summary(m_Ex3_1)

confint(m_Ex3_1,method="Wald")
```

## Target Looking By Item

Next, we investigate item-level (target word) variation in proportion target looking.

### Overall target looking during critical window and baseline window

First, we inspect overall target looking in the critical window and in the baseline window. Note the baseline effects, such that dog and cat are more likely to be fixated during baseline than bird and fish.

```{r}
#average target looking during the baseline and critical window by item for each subject
avg_subj_target_looking_by_item <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num,  age,age_mo, child_gender, trial_order,trial_number,category,target_image,target_typicality_z,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking) %>%
  group_by(sub_num, age,age_mo, child_gender, trial_order,category) %>%
  summarize(N=n(),
            mean_critical_accuracy=mean(mean_target_looking_critical,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(mean_target_looking_critical,na.rm=T)/sqrt(N),
            lower_ci=mean_critical_accuracy-ci,
            upper_ci=mean_critical_accuracy+ci,
            mean_baseline_accuracy=mean(mean_target_looking_baseline,na.rm=TRUE),
            baseline_ci=qt(0.975, N-1)*sd(mean_target_looking_baseline,na.rm=T)/sqrt(N),
            lower_baseline_ci=mean_baseline_accuracy-baseline_ci,
            upper_baseline_ci=mean_baseline_accuracy+baseline_ci)

#summarize average target looking across subjects
avg_target_looking_by_item <- avg_subj_target_looking_by_item %>%
  group_by(category) %>%
  summarize(N=n(),
            critical_accuracy=mean(mean_critical_accuracy,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(mean_critical_accuracy,na.rm=T)/sqrt(N),
            lower_ci=critical_accuracy-ci,
            upper_ci=critical_accuracy+ci,
            baseline_accuracy=mean(mean_baseline_accuracy,na.rm=TRUE),
            baseline_ci=qt(0.975, N-1)*sd(mean_baseline_accuracy,na.rm=T)/sqrt(N),
            lower_baseline_ci=baseline_accuracy-baseline_ci,
            upper_baseline_ci=baseline_accuracy+baseline_ci)
avg_target_looking_by_item %>%
  knitr::kable()
```

#### Target looking during the baseline and critical window split by age

```{r}
#summarize average corrected target looking across subject
avg_target_looking_by_item_by_age <- avg_subj_target_looking_by_item %>%
  mutate(age_group=ifelse(age_mo>16,"older than 16 months","younger than 16 months")) %>%
  group_by(age_group,category) %>%
  summarize(N=n(),
            critical_accuracy=mean(mean_critical_accuracy,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(mean_critical_accuracy,na.rm=T)/sqrt(N),
            lower_ci=critical_accuracy-ci,
            upper_ci=critical_accuracy+ci,
            baseline_accuracy=mean(mean_baseline_accuracy,na.rm=TRUE),
            baseline_ci=qt(0.975, N-1)*sd(mean_baseline_accuracy,na.rm=T)/sqrt(N),
            lower_baseline_ci=baseline_accuracy-baseline_ci,
            upper_baseline_ci=baseline_accuracy+baseline_ci)
avg_target_looking_by_item_by_age %>%
  knitr::kable()
```

### Overall baseline-corrected proportion target looking

Next, we investigate item-level variation in word recognition as measured by baseline-corrected proportion target looking (to help account for the baseline difference noted above).

```{r}
#average corrected target looking by item for each subject
avg_subj_corrected_target_looking_by_item <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  mutate(age_group=ifelse(age_mo>16,"older than 16 months","younger than 16 months")) %>%
  distinct(sub_num, months,age_mo,age_group, child_gender, trial_order,trial_number,category,target_image,target_typicality_z,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking) %>%
  group_by(sub_num, age_mo,age_group, child_gender, trial_order,category) %>%
  summarize(N=n(),
            average_corrected_target_looking=mean(corrected_target_looking,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(corrected_target_looking,na.rm=T)/sqrt(N),
            lower_ci=average_corrected_target_looking-ci,
            upper_ci=average_corrected_target_looking+ci)

#summarize average corrected target looking across subject
avg_corrected_target_looking_by_item <- avg_subj_corrected_target_looking_by_item %>%
  group_by(category) %>%
  summarize(N=n(),
            corrected_target_looking=mean(average_corrected_target_looking,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(average_corrected_target_looking,na.rm=T)/sqrt(N),
            lower_ci=corrected_target_looking-ci,
            upper_ci=corrected_target_looking+ci)
avg_corrected_target_looking_by_item %>%
  knitr::kable()
```

#### Baseline-corrected proportion target looking split by age

```{r}
#summarize average corrected target looking across subject
avg_corrected_target_looking_by_item_by_age <- avg_subj_corrected_target_looking_by_item %>%
  group_by(age_group,category) %>%
  summarize(N=n(),
            corrected_target_looking=mean(average_corrected_target_looking,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(average_corrected_target_looking,na.rm=T)/sqrt(N),
            lower_ci=corrected_target_looking-ci,
            upper_ci=corrected_target_looking+ci)
avg_corrected_target_looking_by_item_by_age %>%
  knitr::kable()
```

#### Baseline-corrected proportion target looking split by typicality

```{r}
#average corrected target looking by item by typicality for each subject
avg_subj_corrected_target_looking_by_item_by_typicality <- d %>%
  filter(exclude_participant==0) %>%
  filter(useable_window==1) %>%
  distinct(sub_num, months,age_mo, trial_order,trial_number,typicality_condition,category,target_image,target_typicality_z,mean_target_looking_critical,mean_target_looking_baseline,corrected_target_looking) %>%
  group_by(sub_num, age_mo, trial_order,typicality_condition,category) %>%
  summarize(N=n(),
            average_corrected_target_looking=mean(corrected_target_looking,na.rm=TRUE))
#summarize average corrected target looking across subject
avg_corrected_target_looking_by_item_by_typicality <- avg_subj_corrected_target_looking_by_item_by_typicality %>%
  group_by(typicality_condition,category) %>%
  summarize(N=n(),
            corrected_target_looking=mean(average_corrected_target_looking,na.rm=TRUE),
            ci=qt(0.975, N-1)*sd(average_corrected_target_looking,na.rm=T)/sqrt(N),
            lower_ci=corrected_target_looking-ci,
            upper_ci=corrected_target_looking+ci)
avg_corrected_target_looking_by_item_by_typicality %>%
  knitr::kable()
```

#### Overall baseline-corrected proportion target looking by condition

```{r}
pal <- wes_palette("Rushmore1", n=5)
set.seed(1)
jitterer <- position_jitter(width = .05,seed=1)
p0 <- ggplot(avg_corrected_target_looking_by_typicality,aes(x=condition,y=average_corrected_target_looking, fill=condition))+
  geom_half_violin(data=filter(avg_corrected_target_looking_by_typicality, condition=="atypical"),position = position_nudge(x = -.1, y = 0), width=1,trim = FALSE, alpha = .8,color=NA,side="l")+
  geom_half_violin(data=filter(avg_corrected_target_looking_by_typicality, condition=="typical"),position = position_nudge(x = .1, y = 0), width=1,trim = FALSE, alpha = .8,color=NA,side="r")+
  geom_path(aes(group=sub_num),color="black",fill=NA,alpha=0.15,size=0.75,position=jitterer)+
  geom_point(aes(color=condition,group=sub_num), size = 2.5, alpha=0.15,position=jitterer)+
  geom_point(data=overall_corrected_target_looking_by_typicality,aes(y=corrected_target_looking),color="black",size=5)+
  geom_line(data=overall_corrected_target_looking_by_typicality,aes(y=corrected_target_looking,group=1),color="black",size=3)+
  geom_errorbar(data=overall_corrected_target_looking_by_typicality,aes(y=corrected_target_looking,ymin=lower_ci,ymax=upper_ci),width=0,size=1.2,color="black")+
  #geom_boxplot(outlier.shape = NA, alpha = .5, width = .1, colour = "black")+
  #scale_colour_brewer(palette = "Dark2")+
  #scale_fill_brewer(palette = "Dark2")+
  geom_hline(yintercept=0,linetype="dashed")+
  scale_colour_manual(values=pal[c(3,4)])+
  scale_fill_manual(values=pal[c(3,4)])+
  theme(legend.position="none")+
  xlab("Typicality Condition")+
  ylab("Baseline-Corrected\nProportion Target Looking")+
  theme(axis.title.x = element_text(face="bold", size=20),
        axis.text.x  = element_text(size=16),
        axis.title.y = element_text(face="bold", size=20),
        axis.text.y  = element_text(size=16),
        strip.text.x = element_text(size = 16,face="bold"))


ggsave(here::here("..","figures","baseline_corrected_accuracy_overall.png"),width=7,height=6)
```

#### Baseline-corrected proportion target looking by category

```{r}
pal <- wes_palette("Rushmore1", n=5)
set.seed(1)
jitterer <- position_jitter(width = .05,seed=1)
p2 <- ggplot(avg_corrected_target_looking_category,aes(x=typicality_condition,y=average_corrected_target_looking, fill=typicality_condition))+
  geom_half_violin(data=filter(avg_corrected_target_looking_category, typicality_condition=="atypical"),position = position_nudge(x = -.1, y = 0), width=1,trim = FALSE, alpha = .8,color=NA,side="l")+
  geom_half_violin(data=filter(avg_corrected_target_looking_category, typicality_condition=="typical"),position = position_nudge(x = .1, y = 0), width=1,trim = FALSE, alpha = .8,color=NA,side="r")+
  geom_path(aes(group=sub_num),color="black",fill=NA,alpha=0.05,size=0.75,position=jitterer)+
  geom_point(aes(color=typicality_condition,group=sub_num), size = 2.5, alpha=0.05,position=jitterer)+
  geom_point(data=avg_corrected_target_looking_by_item_by_typicality,aes(y=corrected_target_looking),color="black",size=1.8)+
  geom_line(data=avg_corrected_target_looking_by_item_by_typicality,aes(y=corrected_target_looking,group=1),color="black",size=1.5)+
  geom_errorbar(data=avg_corrected_target_looking_by_item_by_typicality,aes(y=corrected_target_looking,ymin=lower_ci,ymax=upper_ci),width=0,color="black")+
  #geom_boxplot(outlier.shape = NA, alpha = .5, width = .1, colour = "black")+
  #scale_colour_brewer(palette = "Dark2")+
  #scale_fill_brewer(palette = "Dark2")+
  geom_hline(yintercept=0,linetype="dashed")+
  scale_colour_manual(values=pal[c(3,4)])+
  scale_fill_manual(values=pal[c(3,4)])+
  facet_wrap(.~category)+
  theme(legend.position="none")+
  xlab("Typicality Condition")+
  ylab("Baseline-Corrected\nProportion Target Looking")+
  theme(axis.title.x = element_text(face="bold", size=20),
        axis.text.x  = element_text(size=16),
        axis.title.y = element_text(face="bold", size=20),
        axis.text.y  = element_text(size=16),
        strip.text.x = element_text(size = 16,face="bold"))


ggsave(here::here("..","figures","baseline_corrected_accuracy_by_category.png"),width=7,height=6)
```

```{r}
pal <- wes_palette("Rushmore1", n=5)
p1 <- ggplot(avg_corrected_target_looking_by_typicality,aes(mean_age_mo,average_corrected_target_looking,color=condition,group=condition))+
  geom_pointrange(aes(ymin=lower_se,ymax=upper_se), 
                  position=position_jitter(width=0.2),
                  width=0,
                  size=1) +
  geom_hline(yintercept=0,linetype="dashed")+
  geom_smooth(method="lm",color="black",size=1.3)+
  xlab("Age (in months)")+
  ylab("Baseline-Corrected\nProportion Target Looking")+
  #ylim(-0.55,0.5)+
  scale_colour_manual(values=pal[c(3,4)])+
  scale_x_continuous(breaks=seq(12,18,1))+
  facet_wrap(~condition)+
  theme(
    strip.background = element_rect(size=1, colour = "black"),
    strip.text = element_text(size=16,face="bold"),
    axis.title=element_text(size=20,face="bold"),
    axis.text = element_text(size=14))+
  theme(legend.position="none")
ggsave(here::here("figures","age_relationship_baseline_corrected_accuracy_typicality.png"),width=9,height=6)

plot_grid(p1,p2,nrow=1,ncol=2,labels=c("A","B"),size=24)
ggsave(here::here("..","figures","age_category_typicality.png"),width=12,height=6)
```

```{r}
#timecourse plot
pal <- wes_palette("Rushmore1", n=5)
timecourse_plot <- ggplot(summarize_across_subj_cond,aes(corrected_time_centered,accuracy,color=condition))+
  geom_rect(data = data.frame(xmin = 300,
                              xmax = 2800,
                              ymin = -Inf,
                              ymax = Inf),
            aes(x=NULL, y=NULL,xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax,color=NULL),
            fill = "grey", alpha = 0.2)+
  geom_rect(data = data.frame(xmin = -2000,
                              xmax = 0,
                              ymin = -Inf,
                              ymax = Inf),
            aes(x=NULL, y=NULL,xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax,color=NULL),
            fill = "grey", alpha = 0.2)+
  geom_errorbar(aes(ymin=accuracy-se_accuracy,ymax=accuracy+se_accuracy),width=0)+
  geom_point(alpha=0.5)+
  geom_smooth(data=summarize_subj_condition,aes(y=mean_accuracy),method="gam")+
  geom_vline(xintercept=0,size=1.5)+
  geom_hline(yintercept=0.5,size=1.2,linetype="dashed")+
  geom_vline(xintercept=300,linetype="dotted")+
  geom_vline(xintercept=2800,linetype="dotted")+
  geom_vline(xintercept=-2000,linetype="dotted")+
  geom_vline(xintercept=0,linetype="dotted")+
  theme(legend.position = c(0.8,0.15))+
  annotate("text",label="Critical Window",x=1550,y=0.9,size=6)+
  annotate("text",label="Baseline Window",x=-1000,y=0.9,size=6)+
  ylim(0,1)+
  #xlim(-2000,4000)+
  scale_x_continuous(breaks=seq(-2000,4000,1000),limits=c(-2000,4000))+
  scale_colour_manual(values=pal[c(3,4)])+
  ylab("Proportion Target Looking")+
  xlab("Time (centered on target word onset, in ms)")+
  theme(
    strip.background = element_rect(size=1, colour = "black"),
    strip.text = element_text(size=16,face="bold"),
    axis.title=element_text(size=20,face="bold"),
    axis.text = element_text(size=14),
    legend.text=element_text(size=18),
    legend.title=element_text(size=18))
```


```{r}
library(patchwork)

(p0 + p1) / timecourse_plot + 
  plot_annotation(tag_levels = 'A')+
  theme(plot.tag = element_text(size = 18))
ggsave(here::here("..","figures","main_figure.png"),width=12,height=12)
```


